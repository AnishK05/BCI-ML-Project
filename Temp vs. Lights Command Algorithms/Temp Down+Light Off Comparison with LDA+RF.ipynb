{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pp7XI3gn8C5g","PRh6PkIb27OB"],"authorship_tag":"ABX9TyOfO78MprkUu+joxdF2gmhX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Download Datasets"],"metadata":{"id":"5fjj-IOOg3fc"}},{"cell_type":"code","source":["!pip install mne"],"metadata":{"id":"9AQ0dNoLL4uC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download BDF file\n","!wget -O eeg_data_02.bdf https://www.dropbox.com/scl/fi/et82hv39u24ll3brk8n0l/sub-02_ses-01_task-innerspeech_eeg.bdf?rlkey=prc1yt31nk1hb66h1qml4wkti&dl=0\n","!wget -O eeg_data_03.bdf https://www.dropbox.com/scl/fi/252j4sc1ymcibgitg57dv/sub-03_ses-01_task-innerspeech_eeg.bdf?rlkey=26o26pc7dgucbl5y60f9avd8y&dl=0\n","!wget -O eeg_data_04.bdf https://www.dropbox.com/scl/fi/m5nbdcgh2jsp4fqz1vl76/sub-04_ses-01_task-innerspeech_eeg.bdf?rlkey=07j2jydunn4u7nu36zee2nngl&dl=0\n","!wget -O eeg_data_05.bdf https://www.dropbox.com/scl/fi/0ob6affaz1nxyzmpif77r/sub-05_ses-01_task-innerspeech_eeg.bdf?rlkey=x6morhp7kho5xhc1bl5zm40fj&dl=0\n","!wget -O eeg_data_06.bdf https://www.dropbox.com/scl/fi/qgelieb2o3alzsh13kkq9/sub-06_ses-01_task-innerspeech_eeg.bdf?rlkey=suwr5st63vx43o6xzguyait0q&dl=0\n","!wget -O eeg_data_07.bdf https://www.dropbox.com/scl/fi/ln1tbvlcsdw4examr4uwo/sub-07_ses-01_task-innerspeech_eeg.bdf?rlkey=rktp9di84qv6ef8khk6iom84c&dl=0"],"metadata":{"id":"63NgaxkekzIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mne\n","\n","file_path = 'eeg_data_02.bdf'\n","\n","# Read the .bdf file\n","raw = mne.io.read_raw_bdf(file_path, preload=True)\n","\n","# Plot the data (this requires a graphical interface)\n","raw.plot()"],"metadata":{"id":"5er4e0Lv8xKl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Pre-Processing"],"metadata":{"id":"o9tbKWEug-GB"}},{"cell_type":"code","source":["import mne\n","\n","# Function to process each dataset\n","def process_dataset(file_path):\n","    # Read BDF File\n","    raw = mne.io.read_raw_bdf(file_path, preload=True)\n","    # Re-reference\n","    raw.set_eeg_reference(['EXG1', 'EXG2']) # NODE CHANGES HERE: 'EXG1', 'EXG2', EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8'\n","    # Apply bandpass filter (8 to 30 Hz) and Notch filter at 50 Hz\n","    raw.filter(l_freq=8, h_freq=30, fir_design='firwin')\n","    raw = mne.io.Raw.notch_filter(raw, freqs=50)\n","    # Decimate the data to reduce sampling rate to around 254 Hz\n","    raw.resample(254)\n","    # Epoching: Define events and epochs based on experimental design\n","    events = mne.find_events(raw, initial_event=True, consecutive=True, min_duration=0.002)\n","    event_id = dict(Down=32, Right=34) # dict(Up=31, Down=32, Left=33, Right=34)\n","    picks_vir = mne.pick_types(raw.info, eeg=True, include=['EXG1', 'EXG2'], stim=False)\n","    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=-0.5, tmax=4, picks=picks_vir, preload=True, decim = 3, baseline=None)\n","    print(\"*******************************************************************************************************************************************************\")\n","    return epochs\n","\n","# Download and process each dataset\n","epochs_02 = process_dataset('eeg_data_02.bdf')\n","epochs_03 = process_dataset('eeg_data_03.bdf')\n","epochs_04 = process_dataset('eeg_data_04.bdf')\n","epochs_05 = process_dataset('eeg_data_05.bdf')\n","epochs_06 = process_dataset('eeg_data_06.bdf')\n","epochs_07 = process_dataset('eeg_data_07.bdf')\n","\n","# Combine epochs from all datasets\n","all_epochs = mne.concatenate_epochs([epochs_02, epochs_03, epochs_04, epochs_05, epochs_06, epochs_07])"],"metadata":{"id":"6Iq6HSLZSmFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Extraction\n","\n","import numpy as np\n","\n","# Compute PSD using the compute_psd method\n","spectrum = all_epochs.compute_psd(method='welch')\n","data, freqs = spectrum.get_data(return_freqs=True)\n","\n","# Skip conversion to dB, use the power values directly\n","psds_power = data\n","\n","# Mean PSD values across frequencies for each channel\n","features = psds_power.mean(axis=1)"],"metadata":{"id":"MOJPOYcUwqjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Normalization\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(features)"],"metadata":{"id":"iHM2LmuLxD9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dimensionality Reduction\n","\n","from sklearn.decomposition import PCA\n","\n","# Apply PCA for dimensionality reduction\n","pca = PCA(n_components=0.95)  # Keep 95% of variance\n","X_pca = pca.fit_transform(X_scaled)"],"metadata":{"id":"OgVqzH2Jy4UV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Machine Learning Models"],"metadata":{"id":"EazwriO0hIEX"}},{"cell_type":"code","source":["# LDA Model Building\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.model_selection import train_test_split\n","\n","# Preparing labels for classification\n","y = all_epochs.events[:, -1]  # Assuming last column of events array contains the labels\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n","\n","# Class Splits\n","class_priors = [0.5, 0.5];\n","\n","# Create LDA model\n","lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto', priors=class_priors) #try solver='eigen'\n","lda.fit(X_train, y_train)\n","\n","# -------------------------------------------------------------------------------------------------------\n","\n","# Model Validation and Evaluation\n","\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n","\n","# Predict on test data\n","y_pred_lda = lda.predict(X_test)\n","\n","# Evaluate the LDA model\n","accuracy_lda = accuracy_score(y_test, y_pred_lda)\n","conf_matrix_lda = confusion_matrix(y_test, y_pred_lda)\n","class_report_lda = classification_report(y_test, y_pred_lda)\n","\n","print(f\"LDA Accuracy: {accuracy_lda}\\n\")\n","print(f\"LDA Confusion Matrix:\\n{conf_matrix_lda}\\n\")\n","print(f\"LDA Classification Report:\\n{class_report_lda}\\n\")"],"metadata":{"id":"TV8GXiHZy5tc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random Forest Model Building\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Preparing labels for classification\n","y = all_epochs.events[:, -1]  # Assuming last column of events array contains the labels\n","\n","# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n","\n","# Create RF Model\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X_train, y_train)\n","\n","# -------------------------------------------------------------------------------------------------------\n","\n","# Model Validation and Evaluation\n","\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n","\n","# Predict on test data\n","y_pred_rf = rf.predict(X_test)\n","\n","# Evaluate the Random Forest model\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n","class_report_rf = classification_report(y_test, y_pred_rf)\n","\n","print(f\"Random Forest Accuracy: {accuracy_rf}\\n\")\n","print(f\"Random Forest Confusion Matrix:\\n{conf_matrix_rf}\\n\")\n","print(f\"Random Forest Classification Report:\\n{class_report_rf}\\n\")"],"metadata":{"id":"k1vXHmSVWG8q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finding Best RF Parameters"],"metadata":{"id":"pp7XI3gn8C5g"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# Parameters to tune\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","# Grid Search with cross-validation\n","rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n","rf_grid.fit(X_train, y_train)\n","\n","# Use the best estimator for predictions\n","y_pred_rf = rf_grid.best_estimator_.predict(X_test)"],"metadata":{"id":"n2ZBYVT03DMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Print the best parameters and best score\n","print(\"Best Parameters:\", rf_grid.best_params_)\n","print(\"Best Training Score:\", rf_grid.best_score_)\n","\n","# Evaluate on the test set\n","y_pred_rf = rf_grid.best_estimator_.predict(X_test)\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n","class_report_rf = classification_report(y_test, y_pred_rf)\n","\n","# Print test set evaluation metrics\n","print(f\"Random Forest Test Set Accuracy: {accuracy_rf}\")\n","print(f\"Random Forest Confusion Matrix on Test Set:\\n{conf_matrix_rf}\")\n","print(f\"Random Forest Classification Report on Test Set:\\n{class_report_rf}\")\n"],"metadata":{"id":"BxooT5iY3vRT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN Prototype"],"metadata":{"id":"PRh6PkIb27OB"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","\n","# Reshaping the data for CNN input\n","\n","# Accessing the data from the Epochs object\n","data = all_epochs.get_data()\n","# Data is a 3D array of shape (n_epochs, n_channels, n_times)\n","n_epochs, n_channels, n_times = data.shape\n","\n","X_cnn = data.reshape((n_epochs, n_channels, n_times, 1))\n","\n","# Convert y to a continuous range starting from 0\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Convert the encoded labels to categorical (one-hot encoding)\n","y_categorical = to_categorical(y_encoded)\n","\n","# Splitting the data\n","X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_categorical, test_size=0.3, random_state=42)\n","\n","# CNN Model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(n_channels, n_times, 1)))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Conv2D(64, kernel_size=3, activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(len(np.unique(y)), activation='softmax')) # Number of classes\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train_cnn, y_train_cnn, validation_data=(X_test_cnn, y_test_cnn), epochs=10)\n","\n","# Evaluate the model\n","accuracy_cnn = model.evaluate(X_test_cnn, y_test_cnn)[1]\n","print(f\"CNN Model Accuracy: {accuracy_cnn}\")"],"metadata":{"id":"pfiVoqG3m17o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Make predictions\n","y_pred_cnn = model.predict(X_test_cnn)\n","# Convert predictions from one-hot encoded back to labels\n","y_pred_labels = np.argmax(y_pred_cnn, axis=1)\n","\n","# Convert test labels from one-hot encoded back to labels\n","y_test_labels = np.argmax(y_test_cnn, axis=1)\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)\n","print(conf_matrix)\n","\n","# Print classification report\n","print(classification_report(y_test_labels, y_pred_labels))"],"metadata":{"id":"sbU-PKWyuRh1"},"execution_count":null,"outputs":[]}]}